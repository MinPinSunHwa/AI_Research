{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import nd, gpu, gluon, autograd\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import datasets, transforms\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://aws.amazon.com/ko/blogs/aws/sagemaker/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "class Exchange(mx.gluon.data.Dataset):    \n",
    "    def __init__(self,train=False, time_step=28, day=1, normalization_factor=100):        \n",
    "        self.train=train        \n",
    "        self.time_step=time_step        \n",
    "        self.day=day        \n",
    "        self.normalization_factor = normalization_factor        \n",
    "        #self._data_preprocessing()    \n",
    "        def __repr__(self):        \n",
    "            return \"'JPY_to_KRW'\"    \n",
    "        def __getitem__(self, idx):        \n",
    "            return self._data[idx] , self._label[idx]    \n",
    "        def __len__(self):        \n",
    "            return len(self._data)    \n",
    "        def _data_preprocessing(self):        \n",
    "            #JPY data        \n",
    "            data = pd.read_excel(\"datasets/jpy.xls\")        # change the type of data to numpy        \n",
    "            data = np.asarray(data)        \n",
    "            data = data[:,-1:]        \n",
    "            data = np.reshape(data,(-1,self.day))        \n",
    "            data = data / self.normalization_factor        \n",
    "            if self.train:            \n",
    "                self._data = data[:len(data)-self.time_step].astype(np.float32)            \n",
    "                self._label = data[1:len(data)-self.time_step+1].astype(np.float32)        \n",
    "            else:            \n",
    "                self._data = data[len(data)-self.time_step:].astype(np.float32)            \n",
    "                self._label = np.zeros(np.shape(self._data)).astype(np.float32) # __getitem__' is required for proper operation. (It should be the same size as 'self._data' above.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon.rnn.rnn_cell import LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BTC_to_USD(time_step,day,normalization_factor):\n",
    "    dp = Exchange()\n",
    "    training = gluon.data.DataLoader(Exchange(train=True,time_step=time_step, day=day,normalization_factor=normalization_factor), batch_size=time_step) #Loads data from a dataset and returns mini-batches of data.\n",
    "    prediction = gluon.data.DataLoader(Exchange(train=False,time_step=time_step, day=day,normalization_factor=normalization_factor), batch_size=time_step)  # Loads data from a dataset and returns mini-batches of data.\n",
    "    return training, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exchange_rate_model(epoch=1000, time_step=28, day=7, normalization_factor=100, save_period=1000 , load_period=1000 , learning_rate=0.001, ctx=mx.gpu(0)):\n",
    "\n",
    "    ''' 28 time x 1 day '''\n",
    "    #network parameter\n",
    "    time_step = time_step # 28  step\n",
    "    day = day # 1 day\n",
    "    normalization_factor=normalization_factor\n",
    "    num_hidden = 300\n",
    "    training, test = BTC_to_USD(time_step,day,normalization_factor)\n",
    "    path = \"weights/LSTMCell_weights-{}.params\".format(load_period)\n",
    "    model = LSTMCell(num_hidden,day)\n",
    "    model.hybridize()\n",
    "\n",
    "    # weight initialization\n",
    "    if os.path.exists(path):\n",
    "        print(\"loading weights\")\n",
    "        model.load_params(filename=path ,ctx=ctx) # weights load\n",
    "    else:\n",
    "        print(\"initializing weights\")\n",
    "        model.collect_params().initialize(mx.init.Normal(sigma=0.01), ctx=ctx) # weights initialization\n",
    "\n",
    "    trainer = gluon.Trainer(model.collect_params(), \"adam\", {\"learning_rate\": learning_rate})\n",
    "    for i in tqdm(range(1,epoch+1,1)):\n",
    "        for data, label in training:\n",
    "            H_states=nd.zeros(shape=(1, num_hidden), ctx=ctx)\n",
    "            C_states=nd.zeros(shape=(1, num_hidden), ctx=ctx)\n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            data = data.reshape(shape=(-1, time_step, day))\n",
    "            data = nd.transpose(data=data, axes=(1, 0, 2))\n",
    "            loss = 0\n",
    "\n",
    "            with autograd.record():\n",
    "                for j in range(time_step):\n",
    "                    outputs , [H_states , C_states] = model(data[j],[H_states,C_states])\n",
    "                    loss = loss + gluon.loss.L2Loss()(outputs, label[j].reshape(shape=outputs.shape))\n",
    "            loss.backward()\n",
    "            trainer.step(batch_size=1)\n",
    "        cost = nd.mean(loss).asscalar()\n",
    "        print(\" epoch : {} , last batch cost : {}\".format(i,cost))\n",
    "\n",
    "        #weight_save\n",
    "        if i % save_period==0:\n",
    "            if not os.path.exists(\"weights\"):\n",
    "                os.makedirs(\"weights\")\n",
    "\n",
    "            print(\"saving weights\")\n",
    "            model.save_params(\"weights/LSTMCell_weights-{}.params\".format(i))\n",
    "    prediction(test, time_step, day, normalization_factor ,num_hidden, model, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(test_data, time_step, day, normalization_factor, num_hidden, model, ctx):\n",
    "\n",
    "    for data, label in test_data:\n",
    "        H_states = nd.zeros(shape=(1, num_hidden), ctx=ctx)\n",
    "        C_states = nd.zeros(shape=(1, num_hidden), ctx=ctx)\n",
    "        data = data.as_in_context(ctx)\n",
    "        data = data.reshape(shape=(-1, time_step, day))\n",
    "        data = nd.transpose(data=data, axes=(1, 0, 2))\n",
    "        outputs_list=[]\n",
    "        for j in range(time_step):\n",
    "            outputs, [H_states, C_states] = model(data[j], [H_states, C_states])\n",
    "            outputs_list.append(outputs.asnumpy())\n",
    "    outputs_list = np.array(outputs_list) * normalization_factor\n",
    "    outputs_list= np.reshape(outputs_list,(-1,))\n",
    "\n",
    "    print(\"BTC-USD exchange rate prediction.\")\n",
    "    print(\"prediction value : {}\".format(outputs_list[-1]))\n",
    "    print(\"real value : {}\".format(971.66))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2f9a8334f7db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexchange_rate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalization_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_period\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mload_period\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-25037ad5b596>\u001b[0m in \u001b[0;36mexchange_rate_model\u001b[1;34m(epoch, time_step, day, normalization_factor, save_period, load_period, learning_rate, ctx)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnormalization_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalization_factor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mnum_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBTC_to_USD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnormalization_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"weights/LSTMCell_weights-{}.params\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_period\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTMCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_hidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-3d4b2cf1c0ba>\u001b[0m in \u001b[0;36mBTC_to_USD\u001b[1;34m(time_step, day, normalization_factor)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mBTC_to_USD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnormalization_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExchange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgluon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mExchange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnormalization_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalization_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Loads data from a dataset and returns mini-batches of data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgluon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mExchange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnormalization_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalization_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Loads data from a dataset and returns mini-batches of data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\mxnet\\gluon\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, last_batch, batch_sampler, batchify_fn, num_workers)\u001b[0m\n\u001b[0;32m    253\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                     \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequentialSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"shuffle must not be specified if sampler is specified\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\mxnet\\gluon\\data\\dataset.py\u001b[0m in \u001b[0;36m__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exchange_rate_model(epoch=1000, time_step=28, day=7, normalization_factor=100, save_period=1000 , load_period=1000 , learning_rate=0.001, ctx=mx.gpu(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
