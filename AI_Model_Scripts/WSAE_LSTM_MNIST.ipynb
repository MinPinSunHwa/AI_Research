{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 절대 임포트 설정\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "# 필요한 라이브러리들을 임포트\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a839aeb82f4b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정\n",
    "learning_rate_RMSProp = 0.01\n",
    "learning_rate_Gradient_Descent = 0.5\n",
    "training_epochs = 50     # epoch 횟수 (iteration)\n",
    "softmax_classifier_iterations = 1000 # Softmax Classifier iteration 횟수 \n",
    "batch_size = 256          \n",
    "display_step = 1        # 몇 Step마다 log를 출력할지 결정한다.\n",
    "examples_to_show = 10   # reconstruct된 이미지 중 몇개를 보여줄지를 결정한다. \n",
    "       \n",
    "param_sparsity = 0.01\n",
    "param_weight_decay = 0.0001\n",
    "param_sparse_panelty = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularization(weights):\n",
    "    return tf.nn.l2_loss(weights)\n",
    "\n",
    "def Single_Layer_Autoencoder(Input_Layer, n_input, n_hidden):\n",
    "    with tf.name_scope(\"Hidden_Layer\") as scope:\n",
    "        # 히든 레이어 1을 위한 Weights와 Biases\n",
    "        W_ih = tf.Variable(tf.random_normal([n_input, n_hidden]), name = \"Weight_IH\")  # IH = Input_Hidden\n",
    "        b_ih = tf.Variable(tf.random_normal([n_hidden]), name = \"Bias_IH\")\n",
    "        H_Layer = tf.nn.sigmoid(tf.matmul(Input_Layer, W_ih) + b_ih, name = \"Hidden\")     # 히든레이어 1의 activation (sigmoid 함수를 사용)\n",
    "               \n",
    "    with tf.name_scope(\"Reconstructed_Layer\") as scope:\n",
    "        # Output 레이어를 위한 Weights와 Biases\n",
    "        W_hr = tf.Variable(tf.random_normal([n_hidden, n_input]), name = \"Weight_HR\")  # HR = Hidden_Reconstructed\n",
    "        b_hr = tf.Variable(tf.random_normal([n_input]), name = \"Bias_HR\")\n",
    "        X_reconstructed = tf.nn.sigmoid(tf.matmul(H_Layer,W_hr) + b_hr, name = \"Hidden_HR\")   # Output 레이어의 activation (sigmoid 함수를 사용)\n",
    "    \n",
    "    with tf.name_scope(\"cost\") as scope:        \n",
    "    # Autoencoder Optimization을 위한 파라미터들\n",
    "        average_act_hidden = tf.reduce_mean(H_Layer,axis=0)   #Average hidden layer over all data points in X, Page 14 in https://web.stanford.edu/class/cs294a/sparseAutoencoder_2011new.pdf\n",
    "        diff = Input_Layer - X_reconstructed\n",
    "        KL = Kullback_Leibler_divergence(rho, average_act_hidden)\n",
    "        cost= 0.5*tf.reduce_mean(tf.reduce_sum(tf.pow(diff,2),axis=1)) + 0.5*Lambda*(tf.nn.l2_loss(W_ih) + tf.nn.l2_loss(W_hr)) + Beta*tf.reduce_sum(KL)\n",
    "        cost_summary = tf.summary.scalar(\"cost\", cost)\n",
    "        \n",
    "\n",
    "    return H_Layer, X_reconstructed, cost\n",
    "\n",
    "def Kullback_Leibler_divergence(rho, rho_hat):\n",
    "    return rho * tf.log(rho) - rho * tf.log(rho_hat) + (1 - rho) * tf.log(1 - rho) - (1 - rho) * tf.log(1 - rho_hat)\n",
    "\n",
    "def LSTM(x_input, stateSize, n_classes, y):\n",
    "    with tf.name_scope(\"LSTM_graph\") as scope:\n",
    "        \n",
    "        cellState = tf.placeholder(tf.float32, [batch_size, stateSize])\n",
    "        hiddenState = tf.placeholder(tf.float32, [batch_size, stateSize])\n",
    "        initState = rnn.LSTMStateTuple(cellState, hiddenState)\n",
    "        \n",
    "        W = tf.Variable(np.random.rand(stateSize, n_classes), dtype=tf.float32, name=\"weight1\")\n",
    "        bias1 = tf.Variable(np.zeros((1, n_classes)), dtype=tf.float32)\n",
    "        W2 = tf.Variable(np.random.rand(stateSize, n_classes), dtype=tf.float32, name=\"weight2\")\n",
    "        bias2 = tf.Variable(np.zeros((1, n_classes)), dtype=tf.float32)\n",
    "        tf.summary.histogram(name=\"weights\", values=W)\n",
    "        #weights = tf.Variable(tf.random_normal([cell_size, n_classes]))\n",
    "        #biases = tf.Variable(tf.random_normal([n_classes]))\n",
    "        lstm_cell = rnn.BasicLSTMCell(stateSize, forget_bias=1.0, state_is_tuple=True)\n",
    "        #outputs, states = tf.nn.static_rnn(lstm_cell, x_input, dtype=tf.float32)\n",
    "        stateSeries, currentState = rnn.static_rnn(lstm_cell, x_input, initState)\n",
    "        \n",
    "        # calculate loss\n",
    "        logits_series = [tf.matmul(state, W2) + bias2 for state in stateSeries]\n",
    "        prediction_series = [tf.nn.softmax(logits) for logits in logits_series]\n",
    "        \n",
    "        #losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels = labels, logits=logits) for logits, labels in zip(logits_series, y)]\n",
    "        series_stack = tf.stack([tf.transpose(tf.reshape(logits_series, [batch_size, n_classes])), tf.transpose(y, name='Transpose_y')], axis=2, name=\"logit_label_stacks\")\n",
    "        losses = tf.map_fn(lambda logits, labels: tf.nn.sparse_softmax_cross_entropy_with_logits(labels = labels, logits=logits))\n",
    "        total_loss = tf.reduce_mean(losses, name=\"total_loss\")\n",
    "        \n",
    "        #pred = tf.matmul(outputs[-1], weights) + biases\n",
    "        #cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits = pred, labels = y))\n",
    "            \n",
    "    return total_loss, prediction_series, currentState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = param_sparsity\n",
    "Lambda = param_weight_decay\n",
    "Beta = param_sparse_panelty\n",
    "\n",
    "# 학습에 필요한 변수들 설정\n",
    "with tf.name_scope(\"Tensor_initialize\"):\n",
    "    X = tf.placeholder(\"float\", [None, 784], name = \"Input\")    # Input 데이터 설정\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10], name = \"True_Output\")   # True Output\n",
    "    \n",
    "    batch_X = tf.placeholder(\"float\", [None, 784], name = \"Input\")    # Input 데이터 설정\n",
    "    batch_y_ = tf.placeholder(tf.float32, [None, 10], name = \"True_Output\")   # True Output\n",
    "\n",
    "with tf.name_scope(\"Auto_Encoder_01\"):\n",
    "    H1, O1, cost1 = Single_Layer_Autoencoder(X, 784, 400)\n",
    "    optmzr1 = tf.train.GradientDescentOptimizer(learning_rate_Gradient_Descent).minimize(cost1)\n",
    "\n",
    "with tf.name_scope(\"Auto_Encoder_02\"):\n",
    "    H2, O2, cost2 = Single_Layer_Autoencoder(H1, 400, 400)\n",
    "    optmzr2 = tf.train.GradientDescentOptimizer(learning_rate_Gradient_Descent).minimize(cost2)\n",
    "\n",
    "with tf.name_scope(\"Auto_Encoder_03\"):\n",
    "    H3, O3, cost3 = Single_Layer_Autoencoder(H2, 400, 400)\n",
    "    optmzr3 = tf.train.GradientDescentOptimizer(learning_rate_Gradient_Descent).minimize(cost3)\n",
    "\n",
    "with tf.name_scope(\"Auto_Encoder_04\"):\n",
    "    H4, O4, cost4 = Single_Layer_Autoencoder(H3, 400, 400)\n",
    "    optmzr4 = tf.train.GradientDescentOptimizer(learning_rate_Gradient_Descent).minimize(cost4)\n",
    "\n",
    "with tf.name_scope(\"LSTM\"):\n",
    "    lstm_X = tf.split(H4, 1, 0)\n",
    "    lstm_cost, lstm_pred, lstm_current = LSTM(lstm_X, 5, 10, y_)\n",
    "    lstm_optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(lstm_cost)\n",
    "    correct_pred = tf.equal(tf.argmax(lstm_pred, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension 1 in both shapes must be equal, but are 256 and 1. Shapes are [10,256] and [10,1].\n\tFrom merging shape 0 with other shapes. for 'LSTM/LSTM_graph/logit_label_stacks' (op: 'Pack') with input shapes: [10,256], [10,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1588\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1589\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1590\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimension 1 in both shapes must be equal, but are 256 and 1. Shapes are [10,256] and [10,1].\n\tFrom merging shape 0 with other shapes. for 'LSTM/LSTM_graph/logit_label_stacks' (op: 'Pack') with input shapes: [10,256], [10,1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a85fce2355df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LSTM\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mlstm_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mlstm_cost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstm_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstm_current\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mlstm_optimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_cost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mcorrect_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-de3c195834f3>\u001b[0m in \u001b[0;36mLSTM\u001b[1;34m(x_input, stateSize, n_classes, y)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m#losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels = labels, logits=logits) for logits, labels in zip(logits_series, y)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mseries_stack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits_series\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Transpose_y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"logit_label_stacks\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_softmax_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"total_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m    872\u001b[0m                                                       expanded_num_dims))\n\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 874\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   5530\u001b[0m     \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5531\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 5532\u001b[1;33m         \"Pack\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[0;32m   5533\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5534\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3412\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3413\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3414\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3416\u001b[0m       \u001b[1;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1754\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1755\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1756\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1757\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1758\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1590\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1591\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1592\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1594\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension 1 in both shapes must be equal, but are 256 and 1. Shapes are [10,256] and [10,1].\n\tFrom merging shape 0 with other shapes. for 'LSTM/LSTM_graph/logit_label_stacks' (op: 'Pack') with input shapes: [10,256], [10,1]."
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "from tqdm import tqdm_notebook\n",
    "from pywt import wavedec, waverec\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"./logs/SAE_test7\")\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    # 변수들을 초기화한다.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Step 1: Stacked Autoencoder pre-training \n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    print(\"total_batch \", total_batch)\n",
    "    # Training을 시작한다.\n",
    "    for epoch in tqdm_notebook(range(training_epochs)):\n",
    "        # 모든 배치들을 돌아가면서(Loop) 학습한다.\n",
    "        _current_cell_state = np.zeros((batch_size, stateSize))\n",
    "        _current_hidden_state = np.zeros((batch_size, stateSize))\n",
    "        print(\"New data, epoch\", epoch)\n",
    "        \n",
    "        for batch_idx in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            coeffs = wavedec(batch_xs, 'haar', level=2)\n",
    "            reconstruct_xs = waverec(coeffs, 'haar')\n",
    "            \n",
    "            # batch 데이터를 이용해서 트레이닝을 진행한다.\n",
    "            \n",
    "            # Stacked Auto-encoder\n",
    "            _, SAE_cost1 = sess.run([optmzr1, cost1], feed_dict={X: reconstruct_xs, y_: batch_ys})\n",
    "            _, SAE_cost2 = sess.run([optmzr2, cost2], feed_dict={X: reconstruct_xs, y_: batch_ys})\n",
    "            _, SAE_cost3 = sess.run([optmzr3, cost3], feed_dict={X: reconstruct_xs, y_: batch_ys})\n",
    "            _, SAE_cost4 = sess.run([optmzr4, cost4], feed_dict={X: reconstruct_xs, y_: batch_ys})                       \n",
    "            \n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run([lstm_cost, lstm_optimizer, lstm_current, lstm_pred], feed_dict={X:reconstruct_xs})\n",
    "                        \n",
    "            summary = sess.run(merged_summary, feed_dict={X: reconstruct_xs, y_: batch_ys})\n",
    "            writer.add_summary(summary, batch_idx)\n",
    "            \n",
    "        # 일정 epoch step마다 로그를 출력한다.\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"SAE cost1=\", \"{:.9f}\".format(SAE_cost1), \"SAE cost2=\", \"{:.9f}\".format(SAE_cost2), \"SAE cost3=\", \"{:.9f}\".format(SAE_cost3), \"SAE cost4=\", \"{:.9f}\".format(SAE_cost4), \"LSTM loss=\", \"{:.9f}\".format(_total_loss))\n",
    "    print(\"Stacked Autoencoder + LSTM training Optimization Finished!\")\n",
    "\n",
    "    # Step 2: test 데이터셋을 autoencoder로 reconstruction 해본다.\n",
    "    reconstructed_image1 = sess.run(O1, feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "    reconstructed_image2 = sess.run(O2, feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "    reconstructed_image3 = sess.run(O3, feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "    hidden_image1 = sess.run(H1, feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "    hidden_image2 = sess.run(H2, feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "    hidden_image3 = sess.run(H3, feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "    \n",
    "\n",
    "    # 원본 이미지와 재구축(reconstructed)된 이미지를 비교한다.\n",
    "    f, a = plt.subplots(7, 10, figsize=(10, 4))\n",
    "    for i in range(examples_to_show):\n",
    "        a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "        a[1][i].imshow(np.reshape(hidden_image1[i], (20, 20)))\n",
    "        a[2][i].imshow(np.reshape(reconstructed_image1[i], (28, 28)))        \n",
    "        a[3][i].imshow(np.reshape(hidden_image2[i], (20, 20)))\n",
    "        a[4][i].imshow(np.reshape(reconstructed_image2[i], (20, 20)))\n",
    "        a[5][i].imshow(np.reshape(hidden_image3[i], (20, 20)))\n",
    "        a[6][i].imshow(np.reshape(reconstructed_image3[i], (20, 20)))\n",
    "    \n",
    "    plt.draw()\n",
    "\n",
    "    #plt.waitforbuttonpress()     # 버튼을 누를때까지 작업 정지 \n",
    "    f.savefig('reconstructed_mnist_image.png')  # reconstruction 결과를 png로 저장한다.    \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
